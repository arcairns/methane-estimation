{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from collections import OrderedDict\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import folium\n",
    "from datetime import date\n",
    "import argparse\n",
    "from glob import iglob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import harp\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as rio \n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "from rasterio.windows import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298fd4f",
   "metadata": {},
   "source": [
    "### 1. Download Sentinel5P data from SentinelSat API\n",
    "\n",
    "Searching Sentinel5p data works best by using a geojson file of your area of interest. For this project, the coordinates of the GHGSat target data is used. Function can be used without the footprint.\n",
    "\n",
    "CH4 products older than 1 year are offline and archived. By making this API call, it will trigger the request to make them available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products(api, product, level, date_range, footprint=None):\n",
    "        \"\"\" Search the API based on polygon and time period. Return the products and metadata.\"\"\"\n",
    "        if footprint is not None:\n",
    "            products = api.query(footprint,\n",
    "                            date=(date_range[0], date_range[1]), \n",
    "                            area_relation='Intersects',\n",
    "                            platformname='Sentinel-5',\n",
    "                            producttype=product,\n",
    "                            processinglevel=level,\n",
    "                            processingmode='Offline'\n",
    "                            )\n",
    "        else: \n",
    "            products = api.query(date=(date_range[0], date_range[1]), \n",
    "                            platformname='Sentinel-5',\n",
    "                            producttype=product,\n",
    "                            processinglevel=level,\n",
    "                            processingmode='Offline'\n",
    "                            )\n",
    "        products_df = api.to_dataframe(products) \n",
    "\n",
    "        return products, products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"/Users/amycairns/Desktop/example_aoi.geojson\"\n",
    "footprint = geojson_to_wkt(read_geojson(path))\n",
    "\n",
    "api = SentinelAPI('s5pguest', 's5pguest', api_url='https://s5phub.copernicus.eu/dhus/') # all users should use these details, not sensitive\n",
    "\n",
    "products, products_df = get_products(api, \n",
    "                                     product='L2__CH4___', \n",
    "                                     footprint= footprint, \n",
    "                                     level='L2', \n",
    "                                     date_range=('20220925', '20220926'))\n",
    "\n",
    "print(len(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14772db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.download_all(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd11e6",
   "metadata": {},
   "source": [
    "## 2. Crop data to area of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_bbx(location):\n",
    "    \"\"\" Retrieve coordinates for the location: minimum latitude, maximim latitude, mininimum longitude and maximum longitude \"\"\" \n",
    "    print(\"Getting coordinates for:\", location)\n",
    "    if location == 'California':\n",
    "         location_bbox = [34.9, 35.1, -118.5, -119] #example location\n",
    "    else:\n",
    "        raise Exception('location {location} is not defined'.format(location))\n",
    "        \n",
    "    coords_dict = {}\n",
    "    coords_dict['min_lat'] = location_bbox[0]\n",
    "    coords_dict['max_lat'] = location_bbox[1]\n",
    "    coords_dict['min_lon'] = location_bbox[2]\n",
    "    coords_dict['max_lon'] = location_bbox[3]\n",
    "\n",
    "    return coords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa988619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'latitude_bounds, longitude_bounds, latitude, longitude, '\\\n",
    "             + 'cloud_fraction, sensor_altitude, sensor_azimuth_angle, sensor_zenith_angle, '\\\n",
    "             + 'solar_azimuth_angle, solar_zenith_angle, '\\\n",
    "             + 'CH4_column_volume_mixing_ratio_dry_air_uncertainty'\n",
    "\n",
    "def aoi_steps(location, degrees):\n",
    "    \"\"\" calculate the steps and degrees for the aoi \"\"\"\n",
    "    location_coords = get_location_bbx(location)\n",
    "\n",
    "    # compute the steps\n",
    "    lat_steps = (location_coords['max_lat'] - location_coords['min_lat'])/degrees\n",
    "    lon_steps = (location_coords['max_lon'] - location_coords['min_lon'])/degrees\n",
    "    lat_steps, lon_steps = int(np.ceil(lat_steps)), int(np.ceil(lon_steps))\n",
    "\n",
    "    print(location_coords['max_lat'], location_coords['min_lat'] + degrees*lat_steps)\n",
    "    print(location_coords['max_lon'], location_coords['min_lon'] + degrees*lon_steps)\n",
    "\n",
    "    return lat_steps, lon_steps, location_coords\n",
    "\n",
    "\n",
    "def retrieve_files(folder_raw):\n",
    "    \"\"\" search for .nc files in the location \"\"\"\n",
    "    path_files = os.path.join(folder_raw, '*.nc')\n",
    "    all_files = sorted(list(iglob(path_files, recursive=True)))\n",
    "\n",
    "    print(\"looking for files at: \", (path_files))\n",
    "    print(\"number of .nc detected: \", len(all_files))\n",
    "\n",
    "    return all_files\n",
    "\n",
    "def get_harp_operations(location,\n",
    "                        degrees = 0.01, \n",
    "                        product = 'L2__CH4___', \n",
    "                        harp_product= 'CH4_column_volume_mixing_ratio_dry_air', \n",
    "                        threshold = 75, \n",
    "                        keep_general=fields):\n",
    "    \"\"\" set up the operations that harp needs to create the grid \"\"\"\n",
    "\n",
    "    # get aoi params\n",
    "    lat_steps, lon_steps, location_coords = aoi_steps(location, degrees)\n",
    "\n",
    "    # define harp operations\n",
    "    ops_string = f\"{harp_product}_validity > {threshold}; \\\n",
    "        derive(datetime_stop {{time}});\\\n",
    "        latitude >= {location_coords['min_lat']-1} [degree_north] ; latitude <= {location_coords['max_lat']+1} [degree_north] ;\\\n",
    "        longitude >= {location_coords['min_lon']-1} [degree_east] ; longitude <= {location_coords['max_lon']+1} [degree_east];\\\n",
    "        bin_spatial({lat_steps+1}, {location_coords['min_lat']}, {degrees}, {lon_steps+1}, {location_coords['min_lon']}, {degrees});\\\n",
    "        derive(latitude {{latitude}}); derive(longitude {{longitude}});\\\n",
    "        keep({harp_product}, {keep_general})\"\n",
    "\n",
    "    print('operations:\\n', ops_string, '\\n')\n",
    "\n",
    "    return ops_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(location, folder_raw, folder_output):\n",
    "    \"\"\" Run the processing and save successful .nc files. \"\"\"\n",
    "    success_files, unsuccessful_files = [], []\n",
    "    print(location)\n",
    "    \n",
    "    ## get files to be processed\n",
    "    all_files = retrieve_files(folder_raw)\n",
    "    print(\"retrieved files\")\n",
    "    \n",
    "    ## get harp operations\n",
    "    ops_string = get_harp_operations(location)\n",
    "\n",
    "    for i, file in enumerate(all_files):\n",
    "        try:\n",
    "            harp_L2_L3 = harp.import_product(file, operations=ops_string, options= 'ch4=bias_corrected')\n",
    "            export_path = '{}{}.{}'.format(folder_output, file.split(\"/\")[-1].replace('L2', 'L3').split('.')[0], 'nc')\n",
    "            print(\"export_path: \", export_path)\n",
    "            harp.export_product(harp_L2_L3, export_path, file_format='netcdf')\n",
    "            success_files.append(file)\n",
    "        except:\n",
    "            unsuccessful_files.append(file)\n",
    "    \n",
    "    print(\"The following files have been successful:\\n\", success_files)\n",
    "    print(\"The cropped data will be stored in:\"+folder_output)\n",
    "    print(\"Warning - The following files have no data in your aoi\\n\", unsuccessful_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "process(location='California',\n",
    "        folder_output='/Users/amycairns/Desktop/',\n",
    "        folder_raw='/Users/amycairns/Desktop/Dissertation_data/GHGSat-observations/Bakersfield/observation-AXuDSFy-769909-arm207@bath.ac.uk-2023-03-15/Sentinel-5p/S5P_OFFL_L2__CH4____20220213T191954_20220213T210124_22479_02_020301_20220215T112215.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44536547",
   "metadata": {},
   "source": [
    "## 3. Resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b81207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_crs(in_path, out_path, new_crs):\n",
    "    \"\"\" Reproject files and update metadata \"\"\"\n",
    "    with rasterio.open(in_path) as source:\n",
    "        source_crs = source.crs\n",
    "        print(source_crs)\n",
    "        transform, width, height = calculate_default_transform(source_crs, new_crs, source.width, source.height, *source.bounds)\n",
    "        kwargs = source.meta.copy()\n",
    "\n",
    "        kwargs.update({\n",
    "            \"driver\": 'GTiff',\n",
    "            'crs': new_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height})\n",
    "        print(source.meta)\n",
    "        \n",
    "        with rasterio.open(out_path, 'w', **kwargs) as dst:\n",
    "            print(out_path)\n",
    "            for i in range(1, source.count + 1):\n",
    "                print(source.count)\n",
    "                reproject(\n",
    "                    source=rasterio.band(source, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=source.transform,\n",
    "                    src_crs=source.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=new_crs,\n",
    "                    resampling=Resampling.nearest)\n",
    "                print(source.crs)\n",
    "    return(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/amycairns/Desktop/Dissertation_data/GHGSat-observations/'\n",
    "locations = ['California', 'Arizona']\n",
    "\n",
    "# folder structure for this loop is: location (Arizona or California) > Observation id\n",
    "for location in locations:\n",
    "    for observation in os.listdir(os.path.join(base_path, location)):\n",
    "        f_name = os.path.splitext(os.path.basename(f))[0]\n",
    "        nc_file = xr.open_dataset(f)\n",
    "        \n",
    "        #select field of interest\n",
    "        ch4 = nc_file['CH4_column_volume_mixing_ratio_dry_air']\n",
    "\n",
    "        #set longitude and latitude dimensions\n",
    "        ch4 = ch4.rio.set_spatial_dims(x_dim='longitude', y_dim='latitude')\n",
    "        ch4.rio.write_crs(\"epsg:4326\", inplace=True) # needs to know the previous crs\n",
    "        out_path = os.path.join(base_path, location, observation, \"Sentinel-5p/crop/\", f_name+\".tiff\")\n",
    "        ch4.rio.to_raster(os.path.join(Sentinel_5_path, out_path))\n",
    "\n",
    "        #Define the CRS projection\n",
    "        if location == \"California\":\n",
    "            crs = \"EPSG:32611\"\n",
    "            change_crs(out_path, out_path, crs)\n",
    "\n",
    "        elif location == \"Arizona\":\n",
    "            crs = \"EPSG:32612\"\n",
    "            change_crs(out_path, out_path, crs)\n",
    "\n",
    "        else: \n",
    "            raise Exception('location is not defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eacd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(path, out_dir, target_resolution): \n",
    "    \n",
    "    with rasterio.open(path) as dataset:\n",
    "        resampling_factor = dataset.transform[0]/target_resolution\n",
    "        if resampling_factor != 1:\n",
    "            # resample data to target pixel size\n",
    "            data = dataset.read(\n",
    "                out_shape=(\n",
    "                    dataset.count,\n",
    "                    int(dataset.height * resampling_factor),\n",
    "                    int(dataset.width * resampling_factor)\n",
    "                ),\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "\n",
    "            # image transform\n",
    "            transform = dataset.transform * dataset.transform.scale(\n",
    "                (dataset.width / data.shape[-1]),\n",
    "                (dataset.height / data.shape[-2])\n",
    "            )\n",
    "            out_meta = dataset.meta.copy()\n",
    "            out_height = int(dataset.height * resampling_factor)\n",
    "            out_width = int(dataset.width * resampling_factor)\n",
    "            crs = dataset.crs\n",
    "            out_meta.update({\"driver\":\"GTiff\",\n",
    "                            \"height\": out_height,\n",
    "                            \"width\": out_width,\n",
    "                            \"transform\": transform,\n",
    "                            \"crs\" : crs})\n",
    "\n",
    "            out_path = os.path.join(out_dir, \"resample_\"+str(resampling_factor)+\"_\"+os.path.basename(path))\n",
    "            with rasterio.open(out_path,\"w\",**out_meta) as dest:\n",
    "                dest.write(data)\n",
    "\n",
    "        else:  \n",
    "            shutil.copy(path, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate all sentinel 5 crop folders for each observation and resample\n",
    "for location in locations:\n",
    "    for observation in os.listdir(os.path.join(base_path, location)):\n",
    "            for file in glob(os.path.join(base_path, location, observation, \"Sentinel-5p/crop/\", \"*.tiff\")):\n",
    "                print(file)\n",
    "                out_dir = os.path.join(base_path, location, observation, \"Sentinel-5p/resample\")\n",
    "                resample(file, out_dir, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "example  = \"file\"\n",
    "\n",
    "with rasterio.open(example) as s5p:\n",
    "    print(s5p.count) \n",
    "    data_array = np.array(s5p.read())\n",
    "print(s5p.bounds)\n",
    "print(s5p.crs)\n",
    "print(np.shape(data_array))\n",
    "\n",
    "plt.imshow(data_array[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6677f",
   "metadata": {},
   "source": [
    "## 3. Crop to 15x20km\n",
    "\n",
    "Unable to use the previous approach since now the data is in tiff files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(mid_height, mid_width, window_height, window_width):\n",
    "    min_height, max_height =  mid_height - (window_height/2), mid_height + (window_height/2) \n",
    "    min_width, max_width = mid_width - (window_width/2), mid_width + (window_width/2)\n",
    "    window = Window.from_slices((int(min_height), int(max_height)),(int(min_width), int(max_width)))\n",
    "    return window\n",
    "\n",
    "for location in locations:\n",
    "    for observation in os.listdir(os.path.join(base_path, location)):\n",
    "            for file in glob(os.path.join(base_path, location, observation, \"Sentinel-5p/resample/resample_*.tiff\")):\n",
    "                with rasterio.open(file) as src:\n",
    "                    # see before\n",
    "                    print(file)\n",
    "                    print(\"width:\", src.width)\n",
    "                    print(\"height\", src.height)\n",
    "                    data_array = np.array(src.read())\n",
    "                    plt.imshow(data_array[0])\n",
    "                    plt.show()\n",
    "\n",
    "                    #set variables\n",
    "                    window_width, window_height = 1500, 2000 # desired pixels in window\n",
    "                    mid_width, mid_height = src.width/2, src.height/2  \n",
    "\n",
    "                    # create and apply the window, and show\n",
    "                    window = create_window(mid_height, mid_width, window_height, window_width)\n",
    "                    arr = src.read(1, window=window)\n",
    "                    print(\"height, width:\", np.shape(arr))\n",
    "                    plt.imshow(arr)\n",
    "                    plt.show()\n",
    "\n",
    "                    #update metadata\n",
    "                    meta = src.meta.copy()\n",
    "                    crs = src.crs\n",
    "                    meta.update({\"driver\":\"GTiff\",\n",
    "                                    \"height\": window_height,\n",
    "                                    \"width\": window_width,\n",
    "                                    \"transform\": src.window_transform(window),\n",
    "                                    \"crs\" : crs})\n",
    "                    print(meta)\n",
    "\n",
    "                    #save windowed version\n",
    "                    with rasterio.open(os.path.join(base_path, location, observation, 'Sentinel-5p/crop_resample.tif'), 'w', **meta) as dst:\n",
    "                        dst.write(src.read(window=window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc361af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "example_path = 'example_path'\n",
    "\n",
    "with rasterio.open(os.path.join(example_path)) as s5p:\n",
    "    data_array = np.array(s5p.read())\n",
    "    print(\"aoi coordinates: \", s5p.bounds)\n",
    "    print(\"crs: \", s5p.crs)\n",
    "    print(\"shape: \", data_array.shape)\n",
    "    print(\"maximum methane value :\", data_array.max())\n",
    "\n",
    "    fig, (axrgb, axhist) = pyplot.subplots(1, 2, figsize=(14,7))\n",
    "    show(data_array[0], ax=axrgb)\n",
    "    show_hist(data_array[0], bins=50, histtype='stepfilled',lw=0.0, stacked=False, alpha=0.3, ax=axhist)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610de62",
   "metadata": {},
   "source": [
    "## 4. Replacing NAs with Gaussian distribution around mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f293457",
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in locations:\n",
    "    for observation in os.listdir(os.path.join(base_path, location)):\n",
    "        for file in glob(os.path.join(base_path, location, observation, \"Sentinel-5p/crop_resample.tif\")):\n",
    "            with rasterio.open(file) as src:\n",
    "                print(file)\n",
    "                data_array = np.array(src.read()[0])\n",
    "                data_array = np.where(data_array == 0.0, np.nan, data_array)\n",
    "                plt.imshow(data_array)\n",
    "                plt.show()\n",
    "                print(data_array)\n",
    "                print(np.shape(data_array))\n",
    "                median = np.nanmedian(data_array)\n",
    "                sd = np.nanstd(data_array)\n",
    "\n",
    "                # using a gaussian as the data is a gaussian distribution\n",
    "                nans = np.where(np.isnan(data_array)) #positions of the nans\n",
    "                nan_length = len(data_array[nans])\n",
    "\n",
    "                rand = np.random.normal(median, sd, nan_length)\n",
    "                for i in range(nan_length):\n",
    "                    data_array[nans[0][i]][nans[1][i]] = rand[i]\n",
    "                plt.imshow(data_array)\n",
    "                plt.show()\n",
    "                np.save(os.path.join(base_path, location, observation, \"Sentinel-5p/low_res_methane.npy\"), data_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
